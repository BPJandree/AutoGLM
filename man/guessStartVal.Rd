% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/autoGLM.R
\name{guessStartVal}
\alias{guessStartVal}
\title{A function to efficiently obtain starting values for numerical optimization procedures. Used to initialize the "warm start" optimization routines in generalizeTospecific. The funciton itself uses a "warm start" algorithm over a growing dataset similar to a sieves estimator for an unbounded parameter space.
When (quasi-)complete seperation is detected in subsamples, the starting values are returned as a vector of zeros.
Only relevant when working with large datasets, (multiple times the size of the example data). Has some robustnes checks, returns a vector of zeros when the solution to the criterion is non-unique and the initial guess lands in a parameter regions of extreme values.
Multicollinear values will be return with a parameter guess of 0.}
\usage{
guessStartVal(Y, X, model = "logit", s1 = 0.25, s2 = s1, c1 = 0.85,
  c2 = c1, tracelevel = 1, memorymanagement = TRUE)
}
\arguments{
\item{Y}{A binary response variable.}

\item{X}{A dataset containing multiple exogenous regressors.}

\item{model}{The model for which starting values should be estimated. Either "logit" or "probit" for the logit or probit model, or "gmm_nlminb" for a logit model estimated with gmm using PORT routines (reliable) or "gmm_bfgs" using the BFGS algorithm (fast, but still very slow compared to option "logit").}

\item{s1}{Share of the sample used for the guess}

\item{s2}{share of the subsample used to initialize the guess. If s2 =0.25, s1 =0.25, the guess is initialized at a .05 share of the entire dataset, or .25 of  s1*datasize.}

\item{c1}{confidence of first sample, see \code{\link{getSamples}}.}

\item{c2}{confidence of subsample, see \code{\link{getSamples}}.
#' @param tracelevel Whether information should be printed during execution. Defaults to 1 for printing, set to 0 for no printing.}

\item{memorymanagement}{TRUE/FALSE indicating whether garbage collection should be forec regularly when memory usage is high. Defaults to TRUE, recommended setting for large datasets.}
}
\value{
A vector of coefficients that can be passed on to numerical optimization algorithms.
}
\description{
This function is called by generalizeToSpecific(), but may also be called by users directly to obtain an initial gues of starting values to be passed on to easygmmlogit().
}
\examples{
set.seed(234)

randomlogit <- simulateLogit(nobs=50000, pars = c(0.25, -0.2, -0.3, 0.1, 0.05, 0.025, 0.01,
                             0.005, 0.005, 0.005,0.005,0.0025,
                             0.0025,0.0025,0.0025,0,0,0,0,0,0))

Y=randomlogit[,1]
X=randomlogit[,-1]



# i5 4570 @ 3.2 GHz
system.time(guessStartVal(Y, X, model="logit"))
# user  system elapsed
0.29    0.00    0.30
system.time(logit(cbind(Y,X)))
# user  system elapsed
0.79    0.00    0.80
# the IWLS algorithm used for glm is already quite fast.

system.time(guessStartVal(Y, X, model="gmm_nlminb"))
# user  system elapsed
40.78    4.17    45.35
system.time(logit(cbind(Y,X), method ="gmm"))
# user  system elapsed
179.52   27.55  207.76
# the difference for gmm is quite large. It pays to do:
system.time(logit(cbind(Y,X), method ="gmm", start=guessStartVal(Y, X, model="logit")))
# user  system elapsed
160.55   21.79  182.48
}

